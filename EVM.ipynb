{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rya-Sanovar/Eulerian-Video-Magnification/blob/main/EVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "VBtvVyqEcvmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import scipy.fftpack as fftpack"
      ],
      "metadata": {
        "id": "MwKlHdCsyx80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riFTXrYu4UOG",
        "outputId": "7dcd7702-9107-4a4a-f49b-36f18dee7417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Necessary Functions"
      ],
      "metadata": {
        "id": "sGH0XI4acy4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWzd8cbwyrd3"
      },
      "outputs": [],
      "source": [
        "#convert RBG to YIQ\n",
        "def rgb2yiq(src):\n",
        "    [rows,cols]=src.shape[:2]\n",
        "    dst=np.zeros((rows,cols,3),dtype=np.float64)\n",
        "    T = np.array([[0.299, 0.587, 0.114], [0.5959, -0.2746, -0.3213], [0.2115, -0.5227, 0.3112]])\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            dst[i, j]=np.dot(T,src[i,j])\n",
        "    return dst\n",
        "\n",
        "#convert YIQ to RBG\n",
        "def yiq2rbg(src):\n",
        "    [rows, cols] = src.shape[:2]\n",
        "    dst=np.zeros((rows,cols,3),dtype=np.float64)\n",
        "    T = np.array([[1, 0.956, 0.619], [1, -0.272, -0.647], [1, -1.106, 1.703]])\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            dst[i, j]=np.dot(T,src[i,j])\n",
        "    return dst\n",
        "\n",
        "#Build Gaussian Pyramid\n",
        "def build_gaussian_pyramid(src,level=3):\n",
        "    s=src.copy()\n",
        "    pyramid=[s]\n",
        "    for i in range(level):\n",
        "        s=cv2.pyrDown(pyramid[i])      \n",
        "        pyramid.append(s)\n",
        "    return pyramid\n",
        "\n",
        "#Build Laplacian Pyramid\n",
        "def build_laplacian_pyramid(src,levels=3):\n",
        "    gaussianPyramid = build_gaussian_pyramid(src, levels)\n",
        "    pyramid=[gaussianPyramid[-1]]\n",
        "    for i in range(levels,0,-1):\n",
        "        size=(gaussianPyramid[i-1].shape[1], gaussianPyramid[i-1].shape[0])\n",
        "        GE=cv2.pyrUp(gaussianPyramid[i], dstsize=size)\n",
        "        L=cv2.subtract(gaussianPyramid[i-1],GE)\n",
        "        pyramid.append(L)\n",
        "    return pyramid\n",
        "\n",
        "#load video from file\n",
        "def load_video(video_filename):\n",
        "    cap=cv2.VideoCapture(video_filename)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    video_tensor=np.zeros((frame_count,height,width,3),dtype='float')\n",
        "    x=0\n",
        "    while cap.isOpened():\n",
        "        ret,frame=cap.read()\n",
        "        if ret is True:\n",
        "            video_tensor[x]=frame\n",
        "            x+=1\n",
        "        else:\n",
        "            break\n",
        "    return video_tensor,fps\n",
        "\n",
        "# apply temporal ideal bandpass filter to gaussian video\n",
        "def temporal_ideal_filter(tensor,low,high,fps,axis=0):\n",
        "    fft=fftpack.fft(tensor,axis=axis)\n",
        "    frequencies = fftpack.fftfreq(tensor.shape[0], d=1.0 / fps)\n",
        "    bound_low = (np.abs(frequencies - low)).argmin()\n",
        "    bound_high = (np.abs(frequencies - high)).argmin()\n",
        "    fft[:bound_low] = 0\n",
        "    fft[bound_high:-bound_high] = 0\n",
        "    fft[-bound_low:] = 0\n",
        "    iff=fftpack.ifft(fft, axis=axis)\n",
        "    return np.abs(iff)\n",
        "\n",
        "# build gaussian pyramid for video\n",
        "def gaussian_video(video_tensor,levels=3):\n",
        "    for i in range(0,video_tensor.shape[0]):\n",
        "        frame=video_tensor[i]\n",
        "        pyr=build_gaussian_pyramid(frame,level=levels)\n",
        "        gaussian_frame=pyr[-1]\n",
        "        if i==0:\n",
        "            vid_data=np.zeros((video_tensor.shape[0],gaussian_frame.shape[0],gaussian_frame.shape[1],3))\n",
        "        vid_data[i]=gaussian_frame\n",
        "    return vid_data\n",
        "\n",
        "#amplify the video\n",
        "def amplify_video(gaussian_vid,amplification=50):\n",
        "    return gaussian_vid*amplification\n",
        "\n",
        "#reconstruct video from original video and gaussian video\n",
        "def reconstruct_video(amp_video,origin_video,levels=3):\n",
        "    final_video=np.zeros(origin_video.shape)\n",
        "    print('reconstruction')\n",
        "    print(amp_video.shape)\n",
        "    for i in range(0,amp_video.shape[0]):\n",
        "        img = amp_video[i]\n",
        "        print('img=amp_video[', i, '], img.shape = ', img.shape)\n",
        "        for x in range(levels):\n",
        "            # size=(origin_video[x-1].shape[1], origin_video[x-1].shape[0])\n",
        "            # img=cv2.pyrUp(img, dstsize=size)\n",
        "            img=cv2.pyrUp(img)\n",
        "            print('after range of ', levels, '.',x,' levels, pyrUp, img.shape = ', img.shape, ', origin_video.shape = ', origin_video.shape)\n",
        "        img=cv2.add(img,origin_video[i])\n",
        "        final_video[i]=img\n",
        "    return final_video\n",
        "\n",
        "#save video to files\n",
        "def save_video(video_tensor):\n",
        "    fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "    [height,width]=video_tensor[0].shape[0:2]\n",
        "    writer = cv2.VideoWriter(\"out.avi\", fourcc, 30, (width, height), 1)\n",
        "    for i in range(0,video_tensor.shape[0]):\n",
        "        writer.write(cv2.convertScaleAbs(video_tensor[i]))\n",
        "    writer.release()\n",
        "\n",
        "#magnify color\n",
        "def magnify_color(video_name,low,high,levels=3,amplification=20):\n",
        "    t,f=load_video(video_name)\n",
        "    gau_video=gaussian_video(t,levels=levels)\n",
        "    print(type(gau_video))\n",
        "    print(gau_video.shape)\n",
        "    filtered_tensor=temporal_ideal_filter(gau_video,low,high,f)\n",
        "    print(type(filtered_tensor))\n",
        "    print(filtered_tensor.shape)\n",
        "    amplified_video=amplify_video(filtered_tensor,amplification=amplification)\n",
        "    print(type(amplified_video))\n",
        "    print(amplified_video.shape)\n",
        "    final=reconstruct_video(amplified_video,t,levels=levels)\n",
        "    save_video(final)\n",
        "\n",
        "#build laplacian pyramid for video\n",
        "def laplacian_video(video_tensor,levels=3):\n",
        "    tensor_list=[]\n",
        "    for i in range(0,video_tensor.shape[0]):\n",
        "        frame=video_tensor[i]\n",
        "        pyr=build_laplacian_pyramid(frame,levels=levels)\n",
        "        if i==0:\n",
        "            for k in range(levels):\n",
        "                tensor_list.append(np.zeros((video_tensor.shape[0],pyr[k].shape[0],pyr[k].shape[1],3)))\n",
        "        for n in range(levels):\n",
        "            tensor_list[n][i] = pyr[n]\n",
        "    return tensor_list\n",
        "\n",
        "#butterworth bandpass filter\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    omega = 0.5 * fs\n",
        "    low = lowcut / omega\n",
        "    high = highcut / omega\n",
        "    b, a = signal.butter(order, [low, high], btype='band')\n",
        "    y = signal.lfilter(b, a, data, axis=0)\n",
        "    return y\n",
        "\n",
        "#reconstruct video from laplacian pyramid\n",
        "def reconstruct_from_tensorlist(filter_tensor_list,levels=3):\n",
        "    final=np.zeros(filter_tensor_list[-1].shape)\n",
        "    for i in range(filter_tensor_list[0].shape[0]):\n",
        "        up = filter_tensor_list[0][i]\n",
        "        for n in range(levels-1):\n",
        "            up=cv2.pyrUp(up)+filter_tensor_list[n + 1][i]\n",
        "        final[i]=up\n",
        "    return final\n",
        "\n",
        "#manify motion\n",
        "def magnify_motion(video_name,low,high,levels=3,amplification=20):\n",
        "    t,f=load_video(video_name)\n",
        "    lap_video_list=laplacian_video(t,levels=levels)\n",
        "    filter_tensor_list=[]\n",
        "    for i in range(levels):\n",
        "        filter_tensor=butter_bandpass_filter(lap_video_list[i],low,high,f)\n",
        "        filter_tensor*=amplification\n",
        "        filter_tensor_list.append(filter_tensor)\n",
        "    recon=reconstruct_from_tensorlist(filter_tensor_list)\n",
        "    final=t+recon\n",
        "    save_video(final)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVM"
      ],
      "metadata": {
        "id": "LRY-X33cdEnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown If you are using Colab, upload the video to Colab session's storage from the source\n",
        "#!cp 'drive/My Drive/Self/temp/video.mp4' '.'"
      ],
      "metadata": {
        "id": "7gFT-lzG5MIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure that the no of levels you go down the pyramid, you can go up too.<br>\n",
        "<font color='red'>You can go down `N` levels till the dimension of the `N`th level is even, otherwise for odd, you may encounter an error in reconstruction.</font><br>\n",
        "For eg, if image frame has a shape of `(720, 1280, 3)`, then you can go down 4 levels, where you hit odd<br>\n",
        "(i.e. <br>\n",
        "720/2 = 360<br>\n",
        "360/2 = 180<br>\n",
        "180/2 = 90<br>\n",
        "90/2  = 45)"
      ],
      "metadata": {
        "id": "tafRzihqdBQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Using the `magnify_color` function on video"
      ],
      "metadata": {
        "id": "CUPvGOqLfg-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Choose the low and high for the passband. For face it is best at low=50/60 and high=60/60\n",
        "magnify_color(\"video.mp4\",low=0.83333,high=1,levels=6,amplification=50)"
      ],
      "metadata": {
        "id": "87gKkrDb5nxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A file `out.avi` will be generated and saved in the Colab session storage"
      ],
      "metadata": {
        "id": "JqUH53z0e8yy"
      }
    }
  ]
}